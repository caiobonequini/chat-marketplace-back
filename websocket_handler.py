"""Handler WebSocket para chat em tempo real."""
import asyncio
import json
import uuid
import time
from typing import Dict, Optional, Set, Any
from collections import deque
from fastapi import WebSocket, WebSocketDisconnect

from config import settings
from models.messages import (
    MessageType,
    ClientMessage,
    ServerMessage,
    AudioResponseMessage,
    TranscriptionMessage,
    BotResponseMessage,
    IntentMessage,
    ToolCallMessage,
    ErrorMessage,
)
from dialogflow_service import DialogflowService
from vad_service import VADService
from audio_processor import AudioProcessor
from tts_service import TTSService
from tools.products import ProductsTool
from services.chat_strategy import (
    IChatStrategy,
    NotebookMVStrategy,
    SofyaLLMStrategy,
    DialogFlowDynamicStrategy
)
from utils.logger import get_logger

logger = get_logger(__name__)


class VoiceChatSession:
    """Sess√£o de chat por voz."""
    
    def __init__(self, session_id: str, websocket: WebSocket, chat_config: Optional[Dict] = None):
        """
        Inicializa uma sess√£o de chat.
        
        Args:
            session_id: ID da sess√£o
            websocket: Conex√£o WebSocket
            chat_config: Configura√ß√£o do chat (apiKey, mode, workspaceId, dialogFlowConfig)
        """
        self.session_id = session_id
        self.websocket = websocket
        self.chat_config = chat_config or {}
        self.chat_strategy: Optional[IChatStrategy] = None
        
        # Servi√ßos padr√£o
        self.dialogflow = DialogflowService() if not chat_config or chat_config.get("mode") == "DIALOGFLOW" else None
        self.tts = TTSService()
        self.vad = VADService(
            sample_rate=settings.sample_rate,
            aggressiveness=settings.vad_aggressiveness
        )
        self.audio_processor = AudioProcessor()
        self.products_tool = ProductsTool()
        
        # Estado da sess√£o
        self.is_speaking = False
        self.is_bot_speaking = False
        self.audio_buffer = deque(maxlen=100)  # Buffer de √°udio
        self.current_stream_task: Optional[asyncio.Task] = None
        self.barge_in_flag = asyncio.Event()
        self.message_history: list = []
        self.stt_only_mode = False  # Flag para modo STT apenas (sem Dialogflow)
        
        logger.info(f"Sess√£o criada: {session_id}, mode: {chat_config.get('mode') if chat_config else 'default'}")
    
    async def initialize(self):
        """Inicializa a sess√£o."""
        # Inicializar estrat√©gia de chat baseada na configura√ß√£o
        mode = self.chat_config.get("mode", "DIALOGFLOW")
        api_key = self.chat_config.get("apiKey")
        
        if mode == "RAG" and api_key:
            workspace_id = self.chat_config.get("workspaceId")
            if workspace_id:
                self.chat_strategy = NotebookMVStrategy(
                    api_key=api_key,
                    workspace_id=workspace_id
                )
                await self.chat_strategy.initialize()
            else:
                logger.warning("workspaceId n√£o fornecido para modo RAG")
        
        elif mode == "LLM" and api_key:
            self.chat_strategy = SofyaLLMStrategy(api_key=api_key)
            await self.chat_strategy.initialize()
        
        elif mode == "DIALOGFLOW":
            dialogflow_config = self.chat_config.get("dialogFlowConfig")
            if dialogflow_config:
                # Usar Dialogflow din√¢mico com credenciais em mem√≥ria
                self.chat_strategy = DialogFlowDynamicStrategy(
                    credentials_json=dialogflow_config.get("credentials"),
                    project_id=dialogflow_config.get("projectId"),
                    agent_id=dialogflow_config.get("agentId"),
                    location=dialogflow_config.get("location", "us-central1"),
                    language_code=dialogflow_config.get("languageCode", "pt-BR")
                )
                await self.chat_strategy.initialize()
            else:
                # Usar Dialogflow padr√£o (configura√ß√£o global)
                if self.dialogflow:
                    await self.dialogflow.initialize()
        
        await self.tts.initialize()
        logger.info(f"Sess√£o inicializada: {self.session_id}, strategy: {type(self.chat_strategy).__name__ if self.chat_strategy else 'DialogflowService'}")
    
    async def send_message(self, message: ServerMessage):
        """Envia mensagem para o cliente."""
        try:
            message_dict = message.model_dump(exclude_none=True)
            if message.timestamp is None:
                message_dict['timestamp'] = time.time()
            await self.websocket.send_json(message_dict)
        except Exception as e:
            logger.error(f"Erro ao enviar mensagem: {e}")
    
    async def send_error(self, error: str, details: str = ""):
        """Envia mensagem de erro."""
        error_msg = ErrorMessage(
            type=MessageType.ERROR,
            session_id=self.session_id,
            data={'error': error, 'message': details}
        )
        await self.send_message(error_msg)
    
    async def handle_audio_chunk(self, audio_base64: str):
        """Processa chunk de √°udio recebido."""
        try:
            # Decodificar √°udio
            audio_bytes = self.audio_processor.base64_to_bytes(audio_base64)
            
            # Adicionar ao buffer
            self.audio_buffer.append(audio_bytes)
            
            # Detectar se h√° fala
            is_speech = self.vad.is_speech(audio_bytes)
            
            if is_speech and not self.is_speaking:
                # Usu√°rio come√ßou a falar
                self.is_speaking = True
                logger.info(f"Sess√£o {self.session_id}: Usu√°rio come√ßou a falar")
                
                # Se o bot estiver falando, ativar barge-in
                if self.is_bot_speaking:
                    logger.info(f"Sess√£o {self.session_id}: Barge-in ativado")
                    self.barge_in_flag.set()
                    self.is_bot_speaking = False
                    # Cancelar stream atual se existir
                    if self.current_stream_task and not self.current_stream_task.done():
                        self.current_stream_task.cancel()
            
            elif not is_speech and self.is_speaking:
                # Verificar se √© sil√™ncio prolongado
                # Por enquanto, vamos processar quando receber stop_speaking
                pass
            
        except Exception as e:
            logger.error(f"Erro ao processar chunk de √°udio: {e}")
            await self.send_error("audio_processing_error", str(e))
    
    async def handle_start_speaking(self):
        """Handle quando usu√°rio come√ßa a falar."""
        self.is_speaking = True
        logger.info(f"Sess√£o {self.session_id}: Usu√°rio come√ßou a falar")
        
        # Se o bot estiver falando, ativar barge-in
        if self.is_bot_speaking:
            logger.info(f"Sess√£o {self.session_id}: Barge-in ativado")
            self.barge_in_flag.set()
            self.is_bot_speaking = False
            if self.current_stream_task and not self.current_stream_task.done():
                self.current_stream_task.cancel()
    
    async def handle_stop_speaking(self):
        """Handle quando usu√°rio para de falar."""
        if not self.is_speaking:
            return
        
        self.is_speaking = False
        logger.info(f"Sess√£o {self.session_id}: Usu√°rio parou de falar")
        
        # Se for modo test_stt, n√£o processar com Dialogflow aqui
        # O processamento ser√° feito quando receber a mensagem test_stt
        # Processar √°udio acumulado apenas se n√£o for modo test_stt
        # (o modo test_stt ser√° processado quando receber a mensagem test_stt explicitamente)
    
    async def handle_barge_in(self):
        """Handle interrup√ß√£o expl√≠cita do usu√°rio."""
        logger.info(f"Sess√£o {self.session_id}: Barge-in expl√≠cito")
        self.barge_in_flag.set()
        self.is_bot_speaking = False
        self.is_speaking = True
        
        if self.current_stream_task and not self.current_stream_task.done():
            self.current_stream_task.cancel()
    
    async def handle_test_stt(self):
        """Testa apenas o STT (transcri√ß√£o) sem processar com Dialogflow."""
        try:
            logger.info(f"Sess√£o {self.session_id}: Teste STT solicitado")
            
            # Ativar modo STT apenas
            self.stt_only_mode = True
            
            # Coletar √°udio do buffer
            if len(self.audio_buffer) == 0:
                await self.send_error("test_stt_error", "Nenhum √°udio no buffer. Fale primeiro e depois clique em 'Testar STT'.")
                self.stt_only_mode = False
                return
            
            audio_bytes = b''.join(self.audio_buffer)
            self.audio_buffer.clear()  # Limpar buffer ap√≥s coletar
            
            if len(audio_bytes) == 0:
                await self.send_error("test_stt_error", "√Åudio vazio no buffer.")
                return
            
            # Validar tamanho m√≠nimo
            MIN_AUDIO_SIZE = 1600  # ~100ms a 16kHz
            if len(audio_bytes) < MIN_AUDIO_SIZE:
                await self.send_error("test_stt_error", f"√Åudio muito curto ({len(audio_bytes)} bytes). Fale por mais tempo.")
                return
            
            # Transcrever usando Sofya STT WebSocket
            from services.sofya_stt_websocket import SofyaSTTWebSocket
            import re
            
            api_key = self.chat_config.get("apiKey") if hasattr(self, 'chat_config') else None
            
            # Criar async generator para chunks de √°udio
            async def audio_chunks_generator():
                """Gera chunks de √°udio para o WebSocket."""
                chunk_size = 3200  # ~100ms a 16kHz
                for i in range(0, len(audio_bytes), chunk_size):
                    chunk = audio_bytes[i:i + chunk_size]
                    if chunk:
                        yield chunk
            
            # Callback para transcri√ß√µes parciais
            def on_partial_transcription(text: str):
                """Callback para transcri√ß√µes parciais."""
                if text and len(text.strip()) > 0:
                    logger.debug(f"üìù Transcri√ß√£o parcial (teste STT): {text}")
            
            # Usar WebSocket do Sofya STT
            stt_ws = SofyaSTTWebSocket(api_key=api_key)
            try:
                transcription_result = await stt_ws.transcribe_stream(
                    audio_chunks_generator(),
                    on_partial=on_partial_transcription,
                    timeout=30.0
                )
                
                user_transcription = transcription_result.get("text", "").strip()
                
                # Enviar transcri√ß√£o (mesmo que vazia, para debug)
                transcription_msg = TranscriptionMessage(
                    type=MessageType.TRANSCRIPTION,
                    session_id=self.session_id,
                    data={'text': user_transcription if user_transcription else '[Transcri√ß√£o vazia - possivelmente ru√≠do]'}
                )
                await self.send_message(transcription_msg)
                
                if user_transcription:
                    logger.info(f"‚úÖ Teste STT - Transcri√ß√£o: {user_transcription}")
                else:
                    logger.warning("‚ö†Ô∏è Teste STT - Transcri√ß√£o vazia (possivelmente ru√≠do)")
                    await self.send_error("test_stt_warning", "Transcri√ß√£o vazia. Verifique se voc√™ falou claramente e se o microfone est√° funcionando.")
            
            except Exception as e:
                logger.error(f"Erro no teste STT: {e}", exc_info=True)
                await self.send_error("test_stt_error", f"Erro ao transcrever: {str(e)}")
            finally:
                await stt_ws.close()
                # Desativar modo STT apenas ap√≥s processar
                self.stt_only_mode = False
        
        except Exception as e:
            logger.error(f"Erro ao processar teste STT: {e}", exc_info=True)
            await self.send_error("test_stt_error", str(e))
            self.stt_only_mode = False
    
    async def handle_text_message(self, text: str):
        """Processa mensagem de texto do usu√°rio."""
        try:
            if not text or not text.strip():
                logger.warning("Mensagem de texto vazia")
                return
            
            user_text = text.strip()
            logger.info(f"üìù Mensagem de texto recebida: {user_text}")
            
            # Enviar como transcri√ß√£o (para aparecer no hist√≥rico como "Voc√™")
            transcription_msg = TranscriptionMessage(
                type=MessageType.TRANSCRIPTION,
                session_id=self.session_id,
                data={'text': user_text}
            )
            await self.send_message(transcription_msg)
            
            # Processar com Dialogflow ou estrat√©gia de chat
            if self.dialogflow or isinstance(self.chat_strategy, DialogFlowDynamicStrategy):
                dialogflow_service = self.dialogflow if self.dialogflow else None
                
                if isinstance(self.chat_strategy, DialogFlowDynamicStrategy):
                    dialogflow_service = self.dialogflow or DialogflowService()
                    if not self.dialogflow:
                        await dialogflow_service.initialize()
                
                if dialogflow_service:
                    response = await dialogflow_service.detect_intent_text(
                        session_id=self.session_id,
                        text=user_text
                    )
                    
                    if 'error' in response:
                        await self.send_error("dialogflow_error", response['error'])
                        return
                    
                    if 'text' in response and response['text']:
                        # Enviar resposta do bot
                        bot_response_msg = BotResponseMessage(
                            type=MessageType.BOT_RESPONSE,
                            session_id=self.session_id,
                            data={'text': response['text']}
                        )
                        await self.send_message(bot_response_msg)
                        
                        # Enviar inten√ß√£o se houver
                        if 'intent' in response:
                            intent_msg = IntentMessage(
                                type=MessageType.INTENT,
                                session_id=self.session_id,
                                data=response['intent']
                            )
                            await self.send_message(intent_msg)
                        
                        # Gerar √°udio usando Vertex AI TTS
                        try:
                            logger.info(f"Convertendo texto para √°udio com Vertex AI TTS: {response['text']}")
                            audio_data = await self.tts.synthesize_speech(response['text'])
                            logger.debug(f"√Åudio sintetizado: {len(audio_data)} bytes")
                            
                            if audio_data:
                                audio_base64 = self.audio_processor.bytes_to_base64(audio_data)
                                audio_msg = AudioResponseMessage(
                                    type=MessageType.AUDIO_RESPONSE,
                                    session_id=self.session_id,
                                    data={'audio': audio_base64}
                                )
                                await self.send_message(audio_msg)
                        except Exception as e:
                            logger.error(f"Erro ao sintetizar fala: {e}")
            
            elif self.chat_strategy:
                # Usar estrat√©gia de chat (RAG ou LLM)
                chat_response = await self.chat_strategy.detect_intent_text(
                    session_id=self.session_id,
                    text=user_text
                )
                
                if 'error' in chat_response:
                    await self.send_error("chat_error", chat_response['error'])
                    return
                
                if 'text' in chat_response and chat_response['text']:
                    # Enviar resposta do bot
                    bot_response_msg = BotResponseMessage(
                        type=MessageType.BOT_RESPONSE,
                        session_id=self.session_id,
                        data={'text': chat_response['text']}
                    )
                    await self.send_message(bot_response_msg)
                    
                    # Gerar √°udio TTS
                    try:
                        audio_data = await self.tts.synthesize_speech(chat_response['text'])
                        if audio_data:
                            audio_base64 = self.audio_processor.bytes_to_base64(audio_data)
                            audio_msg = AudioResponseMessage(
                                type=MessageType.AUDIO_RESPONSE,
                                session_id=self.session_id,
                                data={'audio': audio_base64}
                            )
                            await self.send_message(audio_msg)
                    except Exception as e:
                        logger.error(f"Erro ao sintetizar fala: {e}")
        
        except Exception as e:
            logger.error(f"Erro ao processar mensagem de texto: {e}", exc_info=True)
            await self.send_error("text_message_error", str(e))
    
    async def process_audio_stream(self):
        """Processa stream de √°udio acumulado."""
        if len(self.audio_buffer) == 0:
            return
        
        # Limpar flag de barge-in
        self.barge_in_flag.clear()
        
        # Criar async iterator de chunks
        async def audio_chunks_generator():
            """Gera chunks de √°udio do buffer."""
            for chunk in list(self.audio_buffer):
                # Verificar barge-in
                if self.barge_in_flag.is_set():
                    logger.info(f"Sess√£o {self.session_id}: Barge-in durante processamento")
                    break
                yield chunk
            # Limpar buffer ap√≥s processar
            self.audio_buffer.clear()
        
        # Processar com Dialogflow
        try:
            self.current_stream_task = asyncio.create_task(
                self._process_dialogflow_stream(audio_chunks_generator())
            )
            await self.current_stream_task
        except asyncio.CancelledError:
            logger.info(f"Sess√£o {self.session_id}: Stream cancelado por barge-in")
        except Exception as e:
            logger.error(f"Erro ao processar stream: {e}")
            await self.send_error("stream_processing_error", str(e))
    
    async def _process_dialogflow_stream(self, audio_chunks):
        """
        Processa stream de √°udio.
        
        Se usar estrat√©gia de chat (RAG/LLM), primeiro transcreve o √°udio e depois envia texto.
        Se usar Dialogflow, processa streaming diretamente.
        """
        try:
            self.is_bot_speaking = True
            
            # Se usar estrat√©gia de chat (RAG/LLM), precisa transcrever primeiro
            if self.chat_strategy and not isinstance(self.chat_strategy, DialogFlowDynamicStrategy):
                # Para RAG/LLM: coletar todo o √°udio, transcrever, e enviar texto
                audio_bytes = b''.join([chunk async for chunk in audio_chunks])
                
                if len(audio_bytes) == 0:
                    logger.warning("Nenhum √°udio coletado")
                    self.is_bot_speaking = False
                    return
                
                # Transcrever usando Sofya Scribe (pode funcionar sem API key)
                from services.scribe_strategy import SofyaScribeStrategy
                import re
                
                api_key = self.chat_config.get("apiKey")
                scribe = SofyaScribeStrategy(api_key=api_key)  # API key opcional
                try:
                    transcription_result = await scribe.transcribe_audio_stream(audio_bytes)
                    transcribed_text = transcription_result.get("text", "").strip()
                    
                    # Validar transcri√ß√£o: ignorar se muito curta (provavelmente ru√≠do)
                    if len(transcribed_text) < 5:
                        logger.warning(f"Transcri√ß√£o muito curta (ru√≠do?): '{transcribed_text}' - ignorando")
                        transcribed_text = ""
                    else:
                        # Validar se n√£o √© apenas caracteres especiais ou n√∫meros isolados
                        clean_text = re.sub(r'[^a-zA-Z√°√†√¢√£√©√®√™√≠√¨√Æ√≥√≤√¥√µ√∫√π√ª√ß√Å√Ä√Ç√É√â√à√ä√ç√å√é√ì√í√î√ï√ö√ô√õ√á\s]', '', transcribed_text)
                        if len(clean_text.strip()) < 3:
                            logger.warning(f"Transcri√ß√£o inv√°lida (apenas ru√≠do?): '{transcribed_text}' - ignorando")
                            transcribed_text = ""
                        else:
                            logger.info(f"‚úÖ Transcri√ß√£o Sofya Scribe (RAG/LLM): {transcribed_text}")
                except Exception as e:
                    logger.error(f"Erro ao transcrever: {e}", exc_info=True)
                    transcribed_text = ""
                finally:
                    await scribe.close()
                
                if not transcribed_text:
                    logger.warning("Transcri√ß√£o vazia")
                    self.is_bot_speaking = False
                    return
                
                # Enviar transcri√ß√£o
                transcription_msg = TranscriptionMessage(
                    type=MessageType.TRANSCRIPTION,
                    session_id=self.session_id,
                    data={'text': transcribed_text}
                )
                await self.send_message(transcription_msg)
                
                # Enviar para estrat√©gia de chat
                chat_response = await self.chat_strategy.send_message(
                    message=transcribed_text,
                    history=self.message_history
                )
                
                # Atualizar hist√≥rico
                self.message_history.append({"role": "user", "content": transcribed_text})
                if chat_response.get("text"):
                    self.message_history.append({"role": "assistant", "content": chat_response["text"]})
                
                response_text = chat_response.get("text", "")
                
                # Gerar √°udio TTS
                if response_text:
                    try:
                        audio_data = await self.tts.synthesize_speech(response_text)
                        audio_base64 = self.audio_processor.bytes_to_base64(audio_data)
                        audio_msg = AudioResponseMessage(
                            type=MessageType.AUDIO_RESPONSE,
                            session_id=self.session_id,
                            data={'audio': audio_base64}
                        )
                        await self.send_message(audio_msg)
                    except Exception as e:
                        logger.error(f"Erro ao sintetizar fala: {e}")
            
            # Se usar Dialogflow (padr√£o ou din√¢mico)
            elif self.dialogflow or isinstance(self.chat_strategy, DialogFlowDynamicStrategy):
                # TRANSCREVER √ÅUDIO usando Sofya Scribe (Marketplace)
                # Coletar todos os chunks de √°udio
                audio_bytes = b''.join([chunk async for chunk in audio_chunks])
                
                if len(audio_bytes) == 0:
                    logger.warning("Nenhum √°udio coletado para transcri√ß√£o")
                    self.is_bot_speaking = False
                    return
                
                # Validar tamanho m√≠nimo de √°udio (evitar processar ru√≠do muito curto)
                MIN_AUDIO_SIZE = 1600  # ~100ms a 16kHz (m√≠nimo para ser considerado fala)
                if len(audio_bytes) < MIN_AUDIO_SIZE:
                    logger.warning(f"√Åudio muito curto ({len(audio_bytes)} bytes) - ignorando como ru√≠do")
                    self.is_bot_speaking = False
                    return
                
                # Transcrever usando Sofya STT WebSocket (streaming em tempo real)
                from services.sofya_stt_websocket import SofyaSTTWebSocket
                import re
                
                api_key = self.chat_config.get("apiKey") if hasattr(self, 'chat_config') else None
                user_transcription = ""
                
                # Criar async generator para chunks de √°udio
                async def audio_chunks_generator():
                    """Gera chunks de √°udio para o WebSocket."""
                    # Dividir √°udio em chunks menores para streaming
                    chunk_size = 3200  # ~100ms a 16kHz (2 bytes por sample)
                    for i in range(0, len(audio_bytes), chunk_size):
                        chunk = audio_bytes[i:i + chunk_size]
                        if chunk:
                            yield chunk
                
                # Callback para transcri√ß√µes parciais (feedback visual)
                # Nota: callback n√£o pode ser async, ent√£o apenas logamos
                def on_partial_transcription(text: str):
                    """Callback para transcri√ß√µes parciais."""
                    if text and len(text.strip()) > 0:
                        logger.debug(f"üìù Transcri√ß√£o parcial recebida: {text}")
                
                # Usar WebSocket do Sofya STT
                stt_ws = SofyaSTTWebSocket(api_key=api_key)
                try:
                    transcription_result = await stt_ws.transcribe_stream(
                        audio_chunks_generator(),
                        on_partial=on_partial_transcription,
                        timeout=30.0
                    )
                    
                    user_transcription = transcription_result.get("text", "").strip()
                    
                    # Validar transcri√ß√£o: ignorar se muito curta (provavelmente ru√≠do)
                    if len(user_transcription) < 5:
                        logger.warning(f"Transcri√ß√£o muito curta (ru√≠do?): '{user_transcription}' - ignorando")
                        user_transcription = ""
                    else:
                        # Validar se n√£o √© apenas caracteres especiais ou n√∫meros isolados
                        clean_text = re.sub(r'[^a-zA-Z√°√†√¢√£√©√®√™√≠√¨√Æ√≥√≤√¥√µ√∫√π√ª√ß√Å√Ä√Ç√É√â√à√ä√ç√å√é√ì√í√î√ï√ö√ô√õ√á\s]', '', user_transcription)
                        if len(clean_text.strip()) < 3:
                            logger.warning(f"Transcri√ß√£o inv√°lida (apenas ru√≠do?): '{user_transcription}' - ignorando")
                            user_transcription = ""
                        else:
                            logger.info(f"‚úÖ Transcri√ß√£o Sofya STT WebSocket: {user_transcription}")
                
                except Exception as e:
                    logger.error(f"Erro ao transcrever com Sofya STT WebSocket: {e}", exc_info=True)
                    user_transcription = ""
                finally:
                    await stt_ws.close()
                
                # Se transcri√ß√£o vazia, n√£o processar (evitar loops e erros)
                if not user_transcription:
                    logger.warning("Transcri√ß√£o vazia - ignorando (provavelmente ru√≠do)")
                    self.is_bot_speaking = False
                    return
                
                # Enviar transcri√ß√£o do usu√°rio ao frontend
                transcription_msg = TranscriptionMessage(
                    type=MessageType.TRANSCRIPTION,
                    session_id=self.session_id,
                    data={'text': user_transcription}
                )
                await self.send_message(transcription_msg)
                logger.info(f"üì§ Transcri√ß√£o do usu√°rio (Sofya Scribe): {user_transcription}")
                
                # Processar com Dialogflow usando TEXTO
                dialogflow_service = self.dialogflow if self.dialogflow else None
                
                if isinstance(self.chat_strategy, DialogFlowDynamicStrategy):
                    dialogflow_service = self.dialogflow or DialogflowService()
                    if not self.dialogflow:
                        await dialogflow_service.initialize()
                
                if dialogflow_service:
                    # Usar detect_intent_text (j√° temos o texto transcrito)
                    response = await dialogflow_service.detect_intent_text(
                        session_id=self.session_id,
                        text=user_transcription
                    )
                    
                    if 'error' in response:
                        await self.send_error("dialogflow_error", response['error'])
                        self.is_bot_speaking = False
                        return
                    
                    # Processar resposta
                    if 'text' in response and response['text']:
                        # Enviar resposta do bot
                        bot_response_msg = BotResponseMessage(
                            type=MessageType.BOT_RESPONSE,
                            session_id=self.session_id,
                            data={'text': response['text']}
                        )
                        await self.send_message(bot_response_msg)
                        
                        # Enviar inten√ß√£o se houver
                        if 'intent' in response:
                            intent_msg = IntentMessage(
                                type=MessageType.INTENT,
                                session_id=self.session_id,
                                data=response['intent']
                            )
                            await self.send_message(intent_msg)
                        
                        # Gerar √°udio usando Vertex AI TTS
                        try:
                            logger.info(f"Convertendo texto para √°udio com Vertex AI TTS: {response['text']}")
                            audio_data = await self.tts.synthesize_speech(response['text'])
                            logger.debug(f"√Åudio sintetizado: {len(audio_data)} bytes")
                            
                            if audio_data:
                                audio_base64 = self.audio_processor.bytes_to_base64(audio_data)
                                audio_msg = AudioResponseMessage(
                                    type=MessageType.AUDIO_RESPONSE,
                                    session_id=self.session_id,
                                    data={'audio': audio_base64}
                                )
                                await self.send_message(audio_msg)
                        except Exception as e:
                            logger.error(f"Erro ao sintetizar fala: {e}")
                
                self.is_bot_speaking = False
            
        except Exception as e:
            logger.error(f"Erro ao processar stream: {e}")
            self.is_bot_speaking = False
            await self.send_error("stream_processing_error", str(e))
    
    async def _handle_tool_calls(self, tool_calls: list):
        """Processa chamadas de ferramentas."""
        for tool_call in tool_calls:
            tool_name = tool_call.get('name', '')
            parameters = tool_call.get('parameters', {})
            
            logger.info(
                f"Sess√£o {self.session_id}: Chamando ferramenta "
                f"{tool_name} com par√¢metros {parameters}"
            )
            
            # Enviar notifica√ß√£o de chamada de ferramenta
            tool_call_msg = ToolCallMessage(
                type=MessageType.TOOL_CALL,
                session_id=self.session_id,
                data={
                    'tool': tool_name,
                    'parameters': parameters
                }
            )
            await self.send_message(tool_call_msg)
            
            # Executar ferramenta
            if tool_name == "search_products":
                result = await self.products_tool.search_products(
                    query=parameters.get('query'),
                    category=parameters.get('category'),
                    min_price=parameters.get('min_price'),
                    max_price=parameters.get('max_price'),
                    limit=parameters.get('limit', 10)
                )
                
                # Enviar resultado (pode ser usado para continuar conversa)
                logger.info(f"Resultado da ferramenta: {result}")
    
    async def cleanup(self):
        """Limpa recursos da sess√£o."""
        if self.current_stream_task and not self.current_stream_task.done():
            self.current_stream_task.cancel()
        self.audio_buffer.clear()
        
        # Limpar estrat√©gia de chat
        if self.chat_strategy:
            try:
                await self.chat_strategy.cleanup()
            except Exception as e:
                logger.error(f"Erro ao limpar estrat√©gia de chat: {e}")
        
        logger.info(f"Sess√£o {self.session_id}: Limpeza conclu√≠da")


class WebSocketManager:
    """Gerenciador de conex√µes WebSocket."""
    
    def __init__(self):
        """Inicializa o gerenciador."""
        self.active_sessions: Dict[str, VoiceChatSession] = {}
        logger.info("WebSocketManager inicializado")
    
    async def connect(self, websocket: WebSocket, chat_config: Optional[Dict] = None) -> str:
        """
        Aceita conex√£o WebSocket e cria sess√£o.
        
        Args:
            websocket: Conex√£o WebSocket
            chat_config: Configura√ß√£o do chat (opcional, pode ser enviada depois)
        
        Returns:
            ID da sess√£o criada
        """
        await websocket.accept()
        session_id = str(uuid.uuid4())
        
        session = VoiceChatSession(session_id, websocket, chat_config)
        await session.initialize()
        
        self.active_sessions[session_id] = session
        
        logger.info(f"Nova conex√£o WebSocket: {session_id}")
        
        # Enviar mensagem de in√≠cio de sess√£o
        session_start_msg = ServerMessage(
            type=MessageType.SESSION_START,
            session_id=session_id,
            data={'session_id': session_id}
        )
        await session.send_message(session_start_msg)
        
        return session_id
    
    async def disconnect(self, session_id: str):
        """Desconecta sess√£o."""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            await session.cleanup()
            del self.active_sessions[session_id]
            logger.info(f"Sess√£o desconectada: {session_id}")
    
    def get_session(self, session_id: str) -> Optional[VoiceChatSession]:
        """Retorna sess√£o pelo ID."""
        return self.active_sessions.get(session_id)
    
    async def handle_message(self, session_id: str, message: dict):
        """Processa mensagem recebida."""
        session = self.get_session(session_id)
        if not session:
            logger.warning(f"Sess√£o n√£o encontrada: {session_id}")
            return
        
        try:
            # Usar parse_message para valida√ß√£o flex√≠vel
            client_msg = ClientMessage.parse_message(message)
            
            # Verificar se √© mensagem de configura√ß√£o
            if client_msg.type == MessageType.SESSION_START and client_msg.data:
                config = client_msg.data
                if config.get("apiKey") or config.get("mode"):
                    # Atualizar configura√ß√£o da sess√£o
                    session.chat_config.update(config)
                    # Reinicializar com nova configura√ß√£o
                    await session.initialize()
                    logger.info(f"Configura√ß√£o atualizada para sess√£o {session_id}: mode={config.get('mode')}")
            
            elif client_msg.type == MessageType.AUDIO_CHUNK:
                audio_data = client_msg.data.get('audio', '') if client_msg.data else ''
                if audio_data:
                    await session.handle_audio_chunk(audio_data)
            
            elif client_msg.type == MessageType.START_SPEAKING:
                await session.handle_start_speaking()
            
            elif client_msg.type == MessageType.STOP_SPEAKING:
                await session.handle_stop_speaking()
            
            elif client_msg.type == MessageType.BARGE_IN:
                await session.handle_barge_in()
            
            elif client_msg.type == MessageType.TEXT_MESSAGE:
                # Mensagem de texto do usu√°rio
                text = client_msg.data.get('text', '') if client_msg.data else ''
                if text:
                    await session.handle_text_message(text)
            
            elif client_msg.type == MessageType.TEST_STT:
                # Teste apenas STT (sem Dialogflow)
                await session.handle_test_stt()
            
            else:
                logger.warning(f"Tipo de mensagem desconhecido: {client_msg.type}")
        
        except Exception as e:
            logger.error(f"Erro ao processar mensagem: {e}")
            await session.send_error("message_processing_error", str(e))


# Inst√¢ncia global do gerenciador
websocket_manager = WebSocketManager()

